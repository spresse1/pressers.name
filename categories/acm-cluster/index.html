<!doctype html><html lang=en><head><title>ACM Cluster - The Electronic Press</title><meta charset=utf-8><meta http-equiv=cache-control content="public"><meta name=robots content="follow, all"><meta name=language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=keywords content><link rel=alternate type=application/rss+xml title="RSS Feed for pressers.name" href=/index.xml><link rel=stylesheet type=text/css media="screen, projection" href=/static/css/base.css><link rel=stylesheet type=text/css media="screen, projection" href=/static/css/cssmenu.css><link rel=stylesheet type=text/css media="screen, projection" href=/static/css/menustyling.css><link rel=stylesheet type=text/css media="screen, projection" href=/static/css/blog.css><link rel=stylesheet type=text/css media=print href=/static/css/print.css></head><body><div id=skip><a href=#content>Skip to Main Content</a></div><div id=leftbar></div><div id=contentwrapper><div id=header><div id=titleimagediv></div><div id=twotraces><div id=twotracesright>&nbsp;</div></div></div><div class=menu id=topmenu><nav><ul class=top-navigation><li><a href=/ title=Home rel=home>Home</a></li><li><a href=http://github.com/spresse1>GitHub</a></li><li><a href=/contact>Contact</a></li></ul></nav></div><div id=onetrace><div id=onetraceleft></div><div id=breadcrumbs class=breadcrumbs><nav><ul class=breadcrumbs><li><a href=/>Home</a></li><li><a href=/categories/>Categories</a></li><li><a href=/categories/acm-cluster/>ACM Cluster</a></li></ul></nav></div></div><div id=bodywrapper><div id=content><div id=contentborder></div><div id=innercontent><main><div class=pagination-container><nav><ul class=paginator><li class="page-item page-link-current"><a href=/categories/acm-cluster/ aria-label="Page 1" class=page-link id=page-link-current role=button>1</a></li><li class=page-item><a href=/categories/acm-cluster/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/categories/acm-cluster/page/2/ aria-label="Next page" class=page-link role=button>></a></li><li class=page-item><a href=/categories/acm-cluster/page/2/ aria-label="Last page" class=page-link role=button>&#187;</a></li></ul></nav></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-11g.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/17/building-acm-cluster-part-11f-openafs-rpm-build/>Building the ACM Cluster, Part 11g: OpenAFS RPM Build</a></h1><p class=entry-info>Published on <time>Mon, Dec 17, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p><a href=http://www.openafs.org/>OpenAFS</a> is the open source version of the AFS - a file system developed at Carnegie-Mellon University.  AFS has a global, DNS-based address space.  It also has a ton of nice features with respect to allowing users to create and control their own groups and much more granular permissions.  All in all it seems to be a good way to get data into a cluster and to allow users to store and manage documents in a reliable format.</p><h1 id=building-openafs>Building OpenAFS</h1><p>I&rsquo;ve saved building OpenAFS for last because it is somewhat more complicated than the other RPM builds we&rsquo;ve done so far, primarily due to some messiness with kernel versions.  Spcifically, the kernel interfaces that OpenAFS-1.6.1 (the current Linux release) were changed from the 2.6 to the 3.x branch.  OpenAFS has sources that are patched for this, but hasn&rsquo;t released them yet.</p><h2 id=getting-source>Getting Source</h2><p>So, to get the proper source, we&rsquo;re going to have to get them from git.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ git clone git://git.openafs.org/openafs.git
</span></span></code></pre></div><p>We then want to …</p></div><a href=/2012/12/17/building-acm-cluster-part-11f-openafs-rpm-build/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-part-11f-zfs-linux.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/16/building-acm-cluster-part-11f-zfs-linux/>Building the ACM Cluster, part 11f: ZFS on Linux</a></h1><p class=entry-info>Published on <time>Sun, Dec 16, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p><a href=http://www.oracle.com/technetwork/server-storage/solaris11/technologies/zfs-338092.html>ZFS</a> is one of those pieces of software that is almost frighteningly good at what it does.  It has a whole slew of features that make it, for many uses, the perfect filesystem.  These include: deduplication, compression, data integrity guarantees (ZFS can detect and repair silent data corruption), copy-on-write architecture and a built in concept of RAID.  The only problem is that the source is under a license incompatible with the linux kernel, so it will never be kernel mainline.  There is, however, the <a href=http://zfsonlinux.org/>ZFS on linux</a> project, which makes it easy to bring ZFS to several linux distributions.</p><h1 id=building-zfs>Building ZFS</h1><p>Download the SPL and ZFS packages from the <a href=http://zfsonlinux.org/>ZFS on Linux</a> homepage.</p><h2 id=building-spl>Building SPL</h2><p>The main ZFS package requires that parts of SPL (the Solaris portability layer) be installed before ZFS can be installed.  So lets start by untaring SPL.  At the time of writing, the most recent version is 0.6.0-rc12:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ tar xf spl-0.6.0-rc12.tar.gz
</span></span></code></pre></div><p>Now, lets build the RPMs:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cd spl-0.6.0-rc12
</span></span><span style=display:flex><span>$ ./configure
</span></span><span style=display:flex><span>$ …</span></span></span></span></span></span></code></pre></div></div><a href=/2012/12/16/building-acm-cluster-part-11f-zfs-linux/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-part-11e-building-ceph.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/16/building-acm-cluster-part-11e-building-ceph/>Building the ACM Cluster, Part 11e: Building Ceph</a></h1><p class=entry-info>Published on <time>Sun, Dec 16, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p><a href=http://ceph.com/>Ceph</a> is a distributed storage engine.  It can be used in a whole number of different ways - for example, as a block device or an object store.  The current version is codenamed argonaut, hence the header image.</p><p>In the ACM cluster, we&rsquo;re using it as the storage engine for VMs.  This makes a lot of sense in our case, as the VMs are going to want to move from machine to machine and this stops them having to copy the disk image.  Ceph also has the advantage of being kernel-mainline, meaning that all the required bits for it are already built into the kernel and building it does not require patching the kernel at all.</p><h1 id=building-rpms>Building RPMs</h1><p>Building the Ceph RPMs is very similar to the other RPM builds we&rsquo;ve already done.  Ceph is extraordinarily kind and provides their own (working!) spec file.  So first off, download the Ceph <a href=http://ceph.com/resources/downloads/>tar.bz2 from here</a>.  Assuming you&rsquo;re using the same ceph 0.48-argonaut version I am, you&rsquo;ll then want to run</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$  tar xvf ceph-0.48argonaut.tar.bz2 …</span></span></code></pre></div></div><a href=/2012/12/16/building-acm-cluster-part-11e-building-ceph/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-myricom-fiber-rpms.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/16/building-myricom-fiber-rpms/>Building the ACM Cluster, Part 11d: Building Myricom fiber RPMs</a></h1><p class=entry-info>Published on <time>Sun, Dec 16, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>Welcome back to my ongoing series on building the JHUACM VM cluster.  In this part, I&rsquo;m going to be focusing on building the RPM driver for the Myricom fiber cards that were given to us with the cluster.  Unfortunately the drivers for this are closed source.  However, through my connections to physics, I was able to get source code to build from.  In short, if you&rsquo;re here looking for drivers, you&rsquo;re out of luck - go talk to Myricom.</p><p>The specific hardware we have is driven by the mx2g driver, so that is what I&rsquo;ll be working on.</p><h1 id=down-the-rabbit-hole>Down the Rabbit Hole</h1><p>The first thing I did when I got the tarball of the driver source was try to build the rpm.  The normal RPM build process is to copy the source tarball and a spec file into rpmbuild.  With these, it was some convoluted, undocumented and inflexible process.  In short, the process was to run &ldquo;make rpm&rdquo;, copy a magic folder somewhere magical, and then run rpmbuild against the spec file.  This also deliberately …</p></div><a href=/2012/12/16/building-myricom-fiber-rpms/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-part-11c-xen-rpms.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/16/building-acm-cluster-part-11c-xen-rpms/>Building the ACM Cluster, Part 11c: Xen RPMs</a></h1><p class=entry-info>Published on <time>Sun, Dec 16, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>Next up,  lets build RPMs of <a href=http://xen.org/>Xen</a>, a hypervisor.  Xen was chosen because on machines which do not have virtualization bits (like the cluster I&rsquo;m building), Xen will do paravirtualization, which is still somewhat quick.Xen also has the concept of clustering and shifting VMs between instances - an important feature in a VM cluster!</p><h1 id=xen-spec-files>Xen Spec Files</h1><p>CentOS 6 no longer has support for Xen.  CentOS decided that they were going to put their weight behind QEMU/KVM as the virtulization solution and thus stopped distributing and supporting Xen.  There are a few third party sites out there hosting packages. But, frankly, I am sufficiently paranoid to want to build them myself.  I also could not find a freely available spec file.  So I <a href=https://github.com/spresse1/acm-vm-cluster/blob/master/xen/xen.spec>wrote my own for Xen</a>.  Hopefully the fact that I simply use the official Xen source and a spec file that is very simple and easy to examine will satisfy those who are as paranoid as I am.</p><h1 id=on-to-building-the-rpm>On to Building the RPM</h1><ol><li>Download <a href=https://raw.github.com/spresse1/acm-vm-cluster/master/xen/xen.spec>a copy of my spec file</a>.  As before put it …</li></ol></div><a href=/2012/12/16/building-acm-cluster-part-11c-xen-rpms/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-part-11b-kernel-rpm-build.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/16/building-acm-cluster-part-11b-kernel-rpm-build/>Building the ACM Cluster, Part 11b: Kernel RPM Build</a></h1><p class=entry-info>Published on <time>Sun, Dec 16, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>If you haven&rsquo;t already done so, read and execute <a href=/2012/12/15/building-acm-cluster-part-11a-setting-rpmbuild-environment/>Building the ACM Cluster, Part 11a: Setting up rpmbuild environment</a>.</p><p>This article will be covering building a new kernel for CentOS and injecting it into xCat&rsquo;s local package repository.  I am covering this because later on we&rsquo;ll need to have a more recent kernel than CentOS comes with by default.  Xen specifically requires a later kernel.  However, when we build kernel modules, we&rsquo;ll want to be building against the same kernel version we&rsquo;re running.</p><h1 id=kernel-spec>Kernel Spec</h1><p>I&rsquo;ve built a kernel spec based on that at ElRepo (downloadable at <code>kernel/el6/SPECS/</code> from any of <a href=http://elrepo.org/tiki/Download>these mirrors</a>).  This builds a kernel package called kernel-ml.  This is so that it can coexist with the CentOS official kernel.  However, I have a different goal - I want to replace the kernel.  I&rsquo;ve therefore created my own <a href=https://github.com/spresse1/acm-vm-cluster/blob/master/kernel/kernel-3.6.spec>branch on my GitHub</a>.  The only difference between this and the official specfile is that I&rsquo;ve removed every …</p></div><a href=/2012/12/16/building-acm-cluster-part-11b-kernel-rpm-build/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-part-11a-setting-rpmbuild-environment.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/15/building-acm-cluster-part-11a-setting-rpmbuild-environment/>Building the ACM Cluster, Part 11a: Setting up rpmbuild environment</a></h1><p class=entry-info>Published on <time>Sat, Dec 15, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>Up to this point, we haven&rsquo;t built any custom software for the cluster.  I&rsquo;ve tried very hard to use mostly off the shelf software.  However, this has to change.  Several of the major components we&rsquo;re going to use (xen, the fiber card driver, ceph) are not available in the CentOS repositories (or are too old).  So we&rsquo;re going to build them ourselves.</p><p>However, rather than build them on a node-by node basis (which would make a single install hours long&mldr;), we&rsquo;re going to build packages.  CentOS uses the rpm package format to distribute prebuilt software.  So we&rsquo;ll be building RPMs.</p><h1 id=where-do-i-build-rpms>Where do I build RPMs?</h1><p>Many resources recommend not building RPMs as root.  This is quite sensible if you&rsquo;re doing it on a machine that can&rsquo;t easily be rebuilt - that way you can&rsquo;t accidentally overwrite an important file.  However, since you </p><h1 id=installing-rpmbuild>Installing rpmbuild</h1><p>The primary tool used to build rpms is called, obviously enough rpmbuild.  We also need a …</p></div><a href=/2012/12/15/building-acm-cluster-part-11a-setting-rpmbuild-environment/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-vm-cluster-part-8-operating-system-image-build.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/15/building-acm-vm-cluster-part-8-operating-system-image-build/>Building the ACM VM Cluster, Part 10: Operating system image build</a></h1><p class=entry-info>Published on <time>Sat, Dec 15, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>Now that we&rsquo;re done with network configuration.  Now, lets actually build an operating system to use on the nodes!</p><h1 id=lets-go-iso-huntin>Lets go ISO Huntin'!</h1><p>The first step in building operating system install images is to get the full operating system images.  Not netboot, but a fully installable version.  For CentOS the <a href="http://www.centos.org/modules/tinycontent/index.php?id=30">mirrors page</a> is a good place to start your hunt.  Personally, I downloaded both DVD images (CentOS-6.3-x86_64-bin-DVD1.iso and CentOS-6.3-x86_64-bin-DVD2.iso), though I suspect that simply the minimal image will cover it.</p><h1 id=import-install-media>Import Install Media</h1><p>Next, we have to import the install media to xCat&rsquo;s NFS filesystem.  To do this, we&rsquo;ll use the <code>copycds</code> command.  <code>copycds</code> takes as arguments simply the ISOs you want to import:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># copycds CentOS-6.3-x86_64-bin-DVD1.iso CentOS-6.3-x86_64-bin-DVD2.iso</span>
</span></span></code></pre></div><p>Sometimes copycds will tell you</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Error: copycds could not identify the ISO supplied, you may wish to try -n &lt;osver&gt;
</span></span></code></pre></div><p>In which case your command will look more like</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># copycds -n …</span></span></span></code></pre></div></div><a href=/2012/12/15/building-acm-vm-cluster-part-8-operating-system-image-build/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/building-acm-cluster-part-8-setting-masquerade-iptables.md><header class=entry-header><h1 class=entry-title><a href=/2012/12/15/building-acm-cluster-part-8-setting-masquerade-iptables/>Building the ACM Cluster, Part 9: Setting up masquerade with iptables</a></h1><p class=entry-info>Published on <time>Sat, Dec 15, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>Alright! Lets get this started again.  There is one last thing we need to do in order to have networking on the cluster functional.  Right now, the nodes inside the cluster can&rsquo;t speak to the outside world.  While we set up the head node to be able to speak to things on every interface, we haven&rsquo;t yet told it how to move traffic from one interface to another.</p><h1 id=making-the-gateway>Making the Gateway</h1><p>In normal clusters, there are three types of notes - workers, gateways and head nodes.  Workers do whatever task the cluster is intended for.  Head noes manage the workers.  And finally, gateways, which allow the worker nodes to communicate with things outside the cluster.</p><p>Gateways are needed because clusters often use IP addresses which are not publicly routeable.  The gateway allows the entire cluster to sit behind one IP address and is in charge of routing traffic properly.  This process is called <a href=http://en.wikipedia.org/wiki/Network_address_translation>Network Address Translation</a>.  In many ways, this makes the gateway like your home router.</p><p>Anyway, …</p></div><a href=/2012/12/15/building-acm-cluster-part-8-setting-masquerade-iptables/>Continue reading</a></article></div><div class=hentry><article itemtype=http://schema.org/Article itemscope id=blog/acm-cluster/adventures-routing-source-based-multi-homed-routing.md><header class=entry-header><h1 class=entry-title><a href=/2012/10/17/adventures-routing-source-based-multi-homed-routing/>Building the ACM Cluster, Part 8: Adventures in Routing: Source Based (Multi-homed) Routing</a></h1><p class=entry-info>Published on <time>Wed, Oct 17, 2012</time>
in ACM, ACM Cluster</p></header><div class=entry-body><p>(This post is related to the ACM cluster build.  However, it is really generic systems stuff and not terribly related to the actual cluster build.  It is much more closely related to quirks of JHU networking.)</p><h1 id=the-problem>The Problem</h1><p>JHU has two distinct networks - firewalled and firewall-free.  (In truth there are more and there are gradations, but these are the two JHUACM has IP allocations on.)  Some services cannot be run form inside the firewalled network.  For these the ACM has a small firewall-free allocation.  Because the cluster will be hosting VMs inside both networks, it needs to be capable of routing traffic from both.  This means doing something called source-based routing or multihomed routing.  This refers to the fact that this machine will have two connections to the internet.  Typically, this is a very rare setup - Multihoming is usually used at the ISP or datacenter level, rather than at the level of the individual box.</p><h1 id=the-solution>The Solution</h1><p>The solution is to convert linux to …</p></div><a href=/2012/10/17/adventures-routing-source-based-multi-homed-routing/>Continue reading</a></article></div><div class=pagination-container><nav><ul class=paginator><li class="page-item page-link-current"><a href=/categories/acm-cluster/ aria-label="Page 1" class=page-link id=page-link-current role=button>1</a></li><li class=page-item><a href=/categories/acm-cluster/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/categories/acm-cluster/page/2/ aria-label="Next page" class=page-link role=button>></a></li><li class=page-item><a href=/categories/acm-cluster/page/2/ aria-label="Last page" class=page-link role=button>&#187;</a></li></ul></nav></div></main></div></div><div id=sidebar><div class=widget><nav><h1>Recent Posts</h1><ul class=entries-reent><li><a href=/2022/04/03/website-hosting-changed/>Website hosting changed</a></li><li><a href=/2022/02/01/enigma-2022/>Enigma 2022</a></li><li><a href=/2021/11/21/getting-new-lenses-lensfun-notes/>Getting new lenses for Lensfun</a></li><li><a href=/2021/10/04/living-germany-converting-drivers-license/>Living in Germany: Converting a Driver's License</a></li><li><a href=/2021/02/08/im-moving-germany/>I'm moving to Germany!</a></li></ul></nav></div><div class=sidebarbender></div><div class=widget><nav><h1>Social Media</h1><ul class=socialmedia><li><a href=https://twitter.com/spresser>Twitter</a></li><li><a href=https://www.linkedin.com/in/steven-presser/>LinkedIn</a></li></ul></nav></div><div class=sidebarbender></div><div class=widget><nav><h1>Categories</h1><ul class=categories><li><a href=/categories/3d-printing/>3D Printing</a></li><li><a href=/categories/acm/>ACM</a></li><li><a href=/categories/acm-cluster/>ACM Cluster</a></li><li><a href=/categories/cyberlaw/>Cyberlaw</a></li><li><a href=/categories/cybersecurity/>Cybersecurity</a></li><li><a href=/categories/germany/>Germany</a></li><li><a href=/categories/infrastructure/>Infrastructure</a></li><li><a href=/categories/life-in-germany/>Life in Germany</a></li><li><a href=/categories/links/>Links</a></li><li><a href=/categories/presentations/>Presentations</a></li><li><a href=/categories/projects/>Projects</a></li><li><a href=/categories/shrubbery/>Shrubbery</a></li></ul></nav></div><div class=sidebarbender></div></div></div><div id=onetracebottom><footer><a href=https://github.com/spresse1/pressers.name>Website source</a><br>Site design by Kyle M.</footer></div></div></body></html>